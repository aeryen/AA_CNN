Stochastic Gradient Riemannian Langevin Dynamics

on the Probability Simplex

Sam Patterson

Gatsby Computational Neuroscience Unit

University College London

spatterson@gatsby.ucl.ac.uk

Yee Whye Teh

Department of Statistics

University of Oxford

y.w.teh@stats.ox.ac.uk

Abstract

In this paper we investigate the use of Langevin Monte Carlo methods on the
probability simplex and propose a new method, Stochastic gradient Riemannian
Langevin dynamics, which is simple to implement and can be applied to large
scale data. We apply this method to latent Dirichlet allocation in an online mini-
batch setting, and demonstrate that it achieves substantial performance improve-
ments over the state of the art online variational Bayesian methods.

1

Introduction

(cid:88)

In recent years there has been increasing interest in probabilistic models where the latent variables
or parameters of interest are discrete probability distributions over K items, i.e. vectors lying in the
probability simplex

∆K = {(π1, . . . , πK) : πk ≥ 0,

πk = 1} ⊂ RK

(1)

k

Important examples include topic models like latent Dirichlet allocation (LDA) [BNJ03], admixture
models in genetics like Structure [PSD00], and discrete directed graphical models with a Bayesian
prior over the conditional probability tables [Hec99].
Standard approaches to inference over the probability simplex include variational inference [Bea03,
WJ08] and Markov chain Monte Carlo methods (MCMC) like Gibbs sampling [GRS96]. In the
context of LDA, many methods have been developed, e.g. variational inference [BNJ03], collapsed
variational inference [TNW07, AWST09] and collapsed Gibbs sampling [GS04]. With the increas-
ingly large scale document corpora to which LDA and other topic models are applied, there has
also been developments of specialised and highly scalable algorithms [NASW09]. Most proposed
algorithms are based on a batch learning framework, where the whole document corpus needs to be
stored and accessed for every iteration. For very large corpora, this framework can be impractical.
Most recently, [Sat01, HBB10, MHB12] proposed online Bayesian variational inference algorithms
(OVB), where on each iteration only a small subset (a mini-batch) of the documents is processed
to give a noisy estimate of the gradient, and a stochastic gradient descent algorithm [RM51] is
employed to update the parameters of interest. These algorithms have shown impressive results on
very large corpora like Wikipedia articles, where it is not even feasible to store the whole dataset in
memory. This is achieved by simply fetching the mini-batch articles in an online manner, processing,
and then discarding them after the mini-batch.
In this paper, we are interested in developing scalable MCMC algorithms for models deﬁned over
the probability simplex. In some scenarios, and particularly in LDA, MCMC algorithms have been
shown to work extremely well, and in fact achieve better results faster than variational inference
on small to medium corpora [GS04, TNW07, AWST09]. However current MCMC methodology

1

have mostly been in the batch framework which, as argued above, cannot scale to the very large
corpora of interest. We will make use of a recently developed MCMC method called stochastic
gradient Langevin dynamics (SGLD) [WT11, ABW12] which operates in a similar online mini-
batch framework as OVB. Unlike OVB and other stochastic gradient descent algorithms, SGLD
is not a gradient descent algorithm. Rather, it is a Hamiltonian MCMC [Nea10] algorithm which
will asymptotically produce samples from the posterior distribution. It achieves this by updating
parameters according to both the stochastic gradients as well as additional noise which forces it to
explore the full posterior instead of simply converging to a MAP conﬁguration.
There are three difﬁculties that have to be addressed, however, to successfully apply SGLD to LDA
and other models deﬁned on probability simplices. Firstly, the probability simplex (1) is compact
and has boundaries that has to be accounted for when an update proposes a step that brings the
vector outside the simplex. Secondly, the typical Dirichlet priors over the probability simplex place
most of its mass close to the boundaries and corners of the simplex. This is particularly the case for
LDA and other linguistic models, where probability vectors parameterise distributions over a larger
number of words, and it is often desirable to use distributions that place signiﬁcant mass on only
a few words, i.e. we want distributions over ∆K which place most of its mass near the boundaries
and corners. This also causes a problem as depending on the parameterisation used, the gradient
required for Langevin dynamics is inversely proportional to entries in π and hence can blow up
when components of π are close to zero. Finally, again for LDA and other linguistic models, we
would like algorithms that work well in high-dimensional simplices.
These considerations lead us to the ﬁrst contribution of this paper in Section 3, which is an inves-
tigation into different ways to parameterise the probability simplex. This section shows that the
choice of a good parameterisation is not obvious, and that the use of the Riemannian geometry of
the simplex [Ama95, GC11] is important in designing Langevin MCMC algorithms. In particular,
we show that an unnormalized parameterisation, using a mirroring trick to remove boundaries, cou-
pled with a natural gradient update, achieves the best mixing performance. In Section 4, we then
show that the SGLD algorithm, using this parameterisation and natural gradient updates, performs
signiﬁcantly better than OVB algorithms [HBB10, MHB12]. Section 2 reviews Langevin dynamics,
natural gradients and SGLD to setup the framework used in the paper, and Section 6 concludes.

2 Review

2.1 Langevin dynamics

Suppose we model a data set x = x1, . . . , xN , with a generative model p(x | θ) = (cid:81)N

i=1 p(xi |
θ) parameterized by θ ∈ RD with prior p(θ) and that our aim is to compute the posterior p(θ |
x). Langevin dynamics [Ken90, Nea10] is an MCMC scheme which produces samples from the
posterior by means of gradient updates plus Gaussian noise, resulting in a proposal distribution
q(θ∗ | θ) as described by Equation 2.

θ∗ = θ +


2

∇θlog p(θ) +

∇θlog p(xi|θ)

+ ζ,

ζ ∼ N (0, I)

(2)

The mean of the proposal distribution is in the direction of increasing log posterior due to the gra-
dient, while the added noise will prevent the samples from collapsing to a single (local) maximum.
A Metropolis-Hastings correction step is required to correct for discretisation error, with proposals
[RS02]. As  tends to zero, the acceptance ratio
accepted with probability min
tends to one as the Markov chain tends to a stochastic differential equation which has p(θ | x) as its
stationary distribution [Ken78].

1, p(θ∗|x)
p(θ|x)

q(θ|θ∗)
q(θ∗|θ)

(cid:16)

(cid:17)

2.2 Riemannian Langevin dynamics

Langevin dynamics has an isotropic proposal distribution leading to slow mixing if the components
of θ have very different scales or if they are highly correlated. Preconditioning can help with this. A
recent approach, the Riemann manifold Metropolis adjusted Langevin algorithm [GC11] uses a user
chosen matrix G(θ) to precondition in a locally adaptive manner. We will refer to their algorithm

2

(cid:32)

N(cid:88)

i=1

(cid:33)

as Riemannian Langevin dynamics (RLD) in this paper. The Riemannian manifold in question is
the family of probability distributions p(x | θ) parameterised by θ, for which the expected Fisher
information matrix Iθ deﬁnes a natural Riemannian metric tensor. In fact any positive deﬁnite matrix
G(θ) deﬁnes a valid Riemannian manifold and hence we are not restricted to using G(θ) = Iθ. This
is important in practice as for many models of interest the expected Fisher information is intractable.
As in Langevin dynamics, RLD consists of a Gaussian proposal q(θ∗ | θ), along with a Metropolis-
Hastings correction step. The proposal distribution can be written as

θ∗ = θ +

µ(θ) + G− 1

2 (θ)ζ,

ζ ∼ N (0, I)

where the jth component of µ(θ) is given by

µ(θ)j =

G−1(θ)

∇θlog p(θ) +

∇θlog p(xi|θ)

(cid:33)(cid:33)

(cid:18)

G−1(θ)

D(cid:88)

k=1

− 2

∂G(θ)

∂θk

G−1(θ)

j

(cid:32)

D(cid:88)

k=1

+

(cid:32)
(cid:0)G−1(θ)(cid:1)


2

(cid:18)

N(cid:88)

i=1

(cid:19)

jk Tr

G−1(θ)

∂G(θ)

∂θk

(3)

(cid:19)

jk

(4)

The ﬁrst term in Equation 4 is now the natural gradient of the log posterior. Whereas the standard
gradient gives the direction of steepest ascent in Euclidean space, the natural gradient gives the
direction of steepest descent taking into account the geometry implied by G(θ). The remaining
terms in Equation 4 describe how the curvature of the manifold deﬁned by G(θ) changes for small
changes in θ. The Gaussian noise in Equation 3 also takes the geometry of the manifold into account,
having scale deﬁned by G− 1

2 (θ).

2.3 Stochastic gradient Riemannian Langevin dynamics

In the Langevin dynamics and RLD algorithms, the proposal distribution requires calculation of the
gradient of the log likelihood w.r.t. θ, which means processing all N items in the data set. For
large data sets this is infeasible, and even for small data sets it may not be the most efﬁcient use of
computation. The stochastic gradient Langevin dynamics (SGLD) algorithm [WT11] replaces the
calculation of the gradient over the full data set, with a stochastic approximation based on a subset
of data. Speciﬁcally at iteration t we sample n data items indexed by Dt, uniformly from the full
data set and replace the exact gradient in Equation 2 with the approximation

∇θlogp(x | θ) ≈ N
|Dt|

∇θlog p(xi|θ)

(5)

(cid:88)

i∈Dt

Also, SGLD does not use a Metropolis-Hastings correction step, as calculating the acceptance prob-
ability would require use of the full data set, hence defeating the purpose of the stochastic gradient
approximation. Convergence to the posterior is still guaranteed as long as decaying step sizes satis-

fying(cid:80)∞

t=1 t = ∞,(cid:80)∞

t < ∞ are used.

t=1 2

In this paper we combine the use of a preconditioning matrix G(θ) as in RLD with this stochastic
gradient approximation, by replacing the exact gradient in Equation 4 with the approximation from
Equation 5. The resulting algorithm, stochastic gradient Riemannian Langevin dynamics (SGRLD),
avoids the slow mixing problems of Langevin dynamics, while still being applicable in a large scale
online setting due to its use of stochastic gradients and lack of Metropolis-Hastings correction steps.

3 Riemannian Langevin dynamics on the probability simplex

In this section, we investigate the issues which arise when applying Langevin Monte Carlo meth-
ods, speciﬁcally the Langevin dynamics and Riemannian Langevin dynamics algorithms, to models
whose parameters lie on the probability simplex. In these experiments, a Metropolis-Hastings cor-
rection step was used. Consider the simplest possible model: a K dimensional probability vector
, and data x = x1, . . . , xN with p(xi = k | π) = πk.
i=1 δ(xi = k). In

π with Dirichlet prior p(π) ∝ (cid:81)K
This results in a Dirchlet posterior p(π | x) ∝ (cid:81)K

, where nk = (cid:80)N

k πnk+αk−1

k παk−1

k

k

3

Parameterisation

θ

∇θlog p(θ|x)

(cid:16)
(cid:80)D
(cid:0)G−1(θ)(cid:1)

G(θ)
G−1(θ)
G−1 ∂G
∂θk
jk Tr

k=1

G−1(cid:17)
(cid:16)

(cid:80)D

k=1

jk

G−1(θ) ∂G

∂θk

Reduced-Mean

(cid:16)

n·

θk = πk

n+α

diag(θ)−1 +

θ − 1 nK +α−1
1−(cid:80)
(cid:0)diag(θ) − θθT(cid:1)

πK
1

k θk

1
n·

(cid:17)

Kθj − 1
Kθj − 1

11T(cid:17)

(cid:16)

n·

πk

πk

k

1
n·

Reduced-Natural

1−(cid:80)K−1
θk = log
(cid:0)diag(π) − ππT(cid:1)
n + α − (n· + Kα) π
1−(cid:80)
diag(π)−1 +
(1−(cid:80)
(1−(cid:80)

1
k πk

−
−

K−1

K−1

k πk)2

1
π2
j
1
π2
j

k πk)2

11T(cid:17)

Expanded-Mean
|θk|(cid:80)
πk =
k=1 |θk|
θ − n·
θ· − 1
n+α−1
−1
diag (θ)
diag (θ)

Expanded-Natural

πk = eθk(cid:80)
diag(cid:0)eθ(cid:1)
k=1 eθk
n + α − n·π − eθ
diag(cid:0)e−θ(cid:1)

−1
−1

e−θj
e−θj

Table 1: Parameterisation Details

k

k θk

our experiments we use a sparse, symmetric prior with αk = 0.1∀k, and sparse count data, setting
K = 10 and n1 = 90, n2 = n3 = 5 and the remaining nk to zero. This is to replicate the sparse
nature of the posterior in many models of interest. The qualitative conclusions we draw are not
sensitive to the precise choice of hyperparameters and data here.
There are various possible ways to parameterise the probability simplex, and the performance of
Langevin Monte Carlo depends strongly on the choice of parameterisation. We consider both the
mean and natural parameter spaces, and in each of these we try both a reduced (K − 1 dimensional)
and expanded (K dimensional) parameterisation, with details as follows.
Reduced-Mean: in the mean parameter space, the most obvious approach is to set θ = π directly,
but there are two problems with this. Though π has K components, it must lie on the simplex, a
K − 1 dimensional space. Running Langevin dynamics or RLD on the full K dimensional param-
eterisation will result in proposals that are off the simplex with probability one. We can incorporate
k=1 πk = 1 by using the ﬁrst K − 1 components as the parameter θ, and set-
k=1 πk. Note however that the proposals can still violate the boundary constraint
0 < πk < 1, and this is particularly problematic when the posterior has mass close to the boundaries.
Expanded-Mean: we can simplify boundary considerations using a redundant parameterisation.
We take as our parameter θ ∈ RK
+ with prior a product of independent Gamma(αk, 1) distributions,
and so the prior on π is still Dirichlet(α).
The boundary conditions 0 < θk can be handled by simply taking the absolute value of the proposed
θ∗. This is equivalent to letting θ take values in the whole of RK, with prior given by Gammas
|θk|(cid:80)
k |θk|, which again results in a Dirichlet(α)

the constraint that(cid:80)K
ting πK = 1 −(cid:80)K−1
p(θ) ∝(cid:81)K
mirrored at 0, p(θ) ∝(cid:81)K

e−θk. π is then given by πk = θk(cid:80)

k=1 |θk|αk−1e−|θk|, and πk =

k=1 θαk−1

eθk
k=1 eθk

eθk(cid:80)K

1+(cid:80)K−1

prior on π. This approach allows us to bypass boundary issues altogether.
Reduced-Natural: in the natural parameter space, the reduced parameterisation takes the form
for k = 1, . . . , K − 1. The prior on θ can be obtained from the Dirichlet(α) prior
πk =
on π using a change of variables. There are no boundary constraints as the range of θk is R.
Expanded-Natural: ﬁnally the expanded-natural parameterisation takes the form πk =
k=1 eθk
for k = 1, . . . , K. As in the expanded-mean parameterisation, we use a product of Gamma priors,
in this case for eθk, so that the prior for π remains Dirichlet(α).
For all parameterisations, we run both Langevin dynamics and RLD. When applying RLD, we
must choose a metric G(θ). For the reduced parameterisations, we can use the expected Fisher
information matrix, but the redundancy in the full parameterisations means that this matrix has rank
K−1 and hence is not invertible. For these parameterisations we use the expected Fisher information
matrix for a Gamma/Poisson model, which is equivalent to the Dirichlet/Multinomial apart from the
fact that the total number of data items is considered to be random as well.
The details for each parameterisation are summarised in Table 1.
In all cases we are interested
in sampling from the posterior distribution on π, while θ is the speciﬁc parameterisation being
used. For the mean parameterisations, the θ−1 term in the gradient of the log-posterior means
that for components of θ which are close to zero, the proposal distribution for Langevin dynamics
(Equation 2) has a large mean, resulting in unstable proposals with a small acceptance probability.
Due to the form of G(θ)−1, the same argument holds for the RLD proposal distribution for the
natural parameterisations. This leaves us with three possible combinations, RLD on the expanded-
mean parameterisation and Langevin dynamics on each of the natural parameterisations.

4

(a) Effective sample size

(b) Samples

Figure 1: Effective sample size and samples. Burn-in iterations is 10,000; thinning factor 100.

To investigate their relative performances we run a small experiment, producing 110,000 samples
from each of the three remaining parameterisations, discarding 10,000 burn-in samples and thinning
the remaining samples by a factor of 100. For the resulting 1000 thinned samples of θ, we calculate
the corresponding samples of π, and compute the effective sample size for each component of π.
This was done for a range of step sizes , and the mean and median effective sample sizes for the
components of π is shown in Figure 1(a).
Figure 1(b) shows the samples from each sampler at their optimal step size of 0.1. The samples
from Langevin dynamics on both natural parameterisations display higher auto-correlation than the
RLD samples produced using the expanded-mean parameterisation, as would be expected from their
lower effective sample sizes. In addition to the increased effective sample size, the expanded-mean
parameterisation RLD sampler has the advantage that it is computationally efﬁcient as G(θ) is a
diagonal matrix. Hence it is this algorithm that we use when applying these techniques to latent
Dirichlet allocation in Section 4.

4 Applying Riemannian Langevin dynamics to latent Dirichlet allocation

Latent Dirichlet Allocation (LDA) [BNJ03] is a hierarchical Bayesian model, most frequently used
to model topics arising in collections of text documents. The model consists of K topics πk, which
are distributions over the words in the collection, drawn from a symmetric Dirichlet prior with
hyper-parameter β. A document d is then modelled by a mixture of topics, with mixing proportion
ηd, drawn from a symmetric Dirichlet prior with hyper-parameter α. The model corresponds to a
generative process where documents are produced by drawing a topic assignment zdi i.i.d. from ηd
for each word wdi in document d, and then drawing the word wdi from the corresponding topic πzdi.
We integrate out η analytically, resulting in the semi-collapsed distribution:

D(cid:89)

K(cid:89)

K(cid:89)

W(cid:89)

p(w, z, π | α, β) =

where as in [TNW07], ndkw = (cid:80)Nd

d=1

Γ (Kα)

Γ (Kα + nd··)

(6)
i=1 δ(wdi = w, zdi = k) and · denotes summation over the

Γ (α)

w=1

k=1

k=1

corresponding index. Conditional on π, the documents are i.i.d., and we can factorise Equation 6

Γ (α + ndk·)

Γ(W β)
Γ(β)W

πβ+n·kw−1

kw

D(cid:89)

p(w, z, π | α, β) = p(π | β)

p(wd, zd | α, π)

where

p(wd, zd,| α, π) =

d=1

Γ (α + ndk·)

Γ (α)

K(cid:89)

k=1

W(cid:89)

w=1

πndkw
kw

5

(7)

(8)

10^−510^−410^−310^−210^−110^001002003004005006007008009001000Step sizeESS  Expanded−Mean RLD medianExpanded−Mean RLD meanReduced−Natural LD medianReduced−Natural LD meanExpanded−Natural LD medianExpanded−Natural LD mean0100200300400500600700800900100010−810−610−410−21000100200300400500600700800900100010−2810−2110−1410−71000100200300400500600700800900100010−1610−1210−810−4100Thinned sample number4.1 Stochastic gradient Riemannian Langevin dynamics for LDA

dent Gamma prior p(θk) ∝ (cid:81)W

As we would like to apply these techniques to large document collections, we use the stochas-
tic gradient version of the Riemannian Langevin dynamics algorithm, as detailed in Section 2.3.
Following the investigation in Section 3 we use the expanded-mean parameterisation. For each
of the K topics πk, we introduce a W -dimensional unnormalised parameter θk with an indepen-
, for w = 1, . . . , W .
We use the mirroring idea as well. The metric G(θ) is then the diagonal matrix G(θ) =
diag (θ11, . . . , θ1W , . . . , θK1, . . . , θKW )
The algorithm runs on mini-batches of documents: at time t it receives a mini-batch of documents
indexed by Dt, drawn at random from the full corpus D. The stochastic gradient of the log posterior
of θ on Dt is shown in Equation 9.

kw e−θkw and set πkw = θkw(cid:80)
w=1 θβw−1
−1.

w θkw

− 1 +

|D|
|Dt|

(cid:88)

d∈Dt

Ezd|wd,θ,α

(cid:21)

− ndk·
θk·

(cid:20) ndkw
(cid:33)

θkw

∂log p(θ | w, β, α)

∂θkw

(cid:32)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)θkw +


2

θkw

≈ β − 1
(cid:88)

|D|
|Dt|

d∈Dt

For this choice of θ and G(θ), we use Equations 3, 4 to give the SGRLD update for θ,

θ∗
kw =

β − θkw +

Ezd|wd,θ,α [ndkw − πkwndk·]

+ (θkw)

1

2 ζkw

(9)

(10)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

where ζkw ∼ N (0, ). Note that the β−1 term in Equation 9 has been replaced with β in Equation 10
as the −1 cancels with the curvature terms as detailed in Table 1. As discussed in Section 3, we
reﬂect moves across the boundary 0 < θkw by taking the absolute value of the proposed update.
Comparing Equation 9 to the gradient for the simple model from Section 3, the observed counts
nk for the simple model have been replaced with the expectation of the latent topic assignment
counts ndkw. To calculate this expectation we use Gibbs sampling on the topic assignments in each
document separately, using the conditional distributions

p(zdi = k | wd, θ, α) =

(11)

(cid:16)
(cid:80)

k

(cid:16)

(cid:17)

(cid:17)

\i
dk·
\i
dk·

α + n

θkwdi

α + n

θkwdi

where \i represents a count excluding the topic assignment variable we are updating.

5 Experiments

d,i q(zdi)(cid:81)

We investigate the performance of SGRLD, with no Metropolis-Hastings correction step, on two
real-world data sets. We compare it to two online variational Bayesian algorithms developed
for latent Dirichlet allocation: online variational Bayes (OVB) [HBB10] and hybrid stochastic
variational-Gibbs (HSVG) [MHB12]. The difference between these two methods is the form of vari-
ational assumption made. OVB assumes a mean-ﬁeld variational posterior, q(η1:D, z1:D, π1:K) =
k q(πk), in particular this means topic assignment variables within the same
document are assumed to be independent, when in reality they will be strongly coupled. In con-
trast HSVG collapses ηd analytically and uses a variational posterior of the form q(z1:D, π1:K) =
k q(πk), which allows dependence within the components of zd. This more complicated
posterior requires Gibbs sampling in the variational update step for zd, and we combined the code
for OVB [HBB10], with the Gibbs sampling routine from our SGRLD code to implement HSVG.

(cid:81)
d q(ηd)(cid:81)
(cid:81)
d q(zd)(cid:81)

5.1 Evaluation Method

The predictive performance of the algorithms can be measured by looking at the probability they
assign to unseen data. A metric frequently used for this purpose is perplexity, the exponentiated
cross entropy between the trained model probability distribution and the empirical distribution of
the test data. For a held-out document wd and a training set W, the perplexity is given by

(cid:26)

(cid:80)nd··
i=1 log p(wdi | W, α, β)

(cid:27)

perp(wd | W, α, β) = exp

−

.

(12)

nd··

6

This requires calculating p(wdi
ηd, π1, . . . , πK and topic assignments zd, to give

| W, α, β), which is done by marginalising out the parameters

p(wdi | W, α, β) = Eηd,π

ηdkπkwdi

(13)

(cid:35)

(cid:34)(cid:88)

k

We use a document completion approach [WMSM09], partitioning the test document wd into two
sets of words, wtrain
to estimate ηd for the test document, then calculating the
d
perplexity on wtest
To calculate the perplexity for SGRLD, we integrate η analytically, so Equation 13 is replaced by

d using this estimate.

and using wtrain

, wtest

d

d

(cid:34)

(cid:34)(cid:88)

(cid:35)(cid:35)

p(wdi | wtrain

d

,W, α, β) = Eπ|W,β

E
ztrain
d

|π,α

ˆηdkπkwdi

where

ˆηdk := p(ztest

di = k | ztrain

d

k

, α) =

ntrain
dk· + α
ntrain
d·· + Kα

.

(14)

(15)

(cid:34)(cid:88)

(cid:35)

≈(cid:88)

We estimate these expectations using the samples we obtain for π from the Markov chain produced
by SGRLD, and samples for ztrain
For OVB and HSVG, we estimate Equation 13 by replacing the true posterior p(η, β) with q(η, β).

produced by Gibbs sampling the topic assignments on wtrain

.

d

d

p(wdi | W, α, β) = Ep(ηd,π|W,α,β)

ηdkπkwdi

Eq(ηd) [ηdk] Eq(πk) [πkwdi ]

(16)

We estimate the perplexity directly rather than use a variational bound [HBB10] so that we can
compare results of the variational algorithms to those of SGRLD.

k

k

5.2 Results on NIPS corpus

The ﬁrst experiment was carried out on the collection of NIPS papers from 1988-2003 [GCPT07].
This corpus contains 2483 documents, which is small enough to run all three algorithms in batch
mode and compare their performance to that of collapsed Gibbs sampling on the full collection.
Each document was split 80/20 into training and test sets, the training portion of all 2483 documents
were used in each update step, and the perplexity was calculated on the test portion of all docu-
ments. Hyper-parameters α and β were both ﬁxed to 0.01, and 50 topics were used. A step-size
schedule of the form t = (a ∗ (1 + t
b ))−c was used. Perplexities were estimated for a range of step
size parameters, and for 1, 5 and 10 document updates per topic parameter update. For OVB the
document updates are ﬁxed point iterations of q(zd) while for HSVG and SGRLD they are Gibbs
updates of zd, the ﬁrst half of which were discarded as burn-in. These numbers of document updates
were chosen as previous investigation of the performance of HSVG for varying numbers of Gibbs
updates has shown that 6-10 updates are sufﬁcient [MHB12] to achieve good performance.
Figure 2(a) shows the lowest perplexities achieved along with the corresponding parameter settings.
As expected, CGS achieves the lowest perplexities. It is surprising that HSVG performs slightly
worse than OVB on this data set. As it uses a less restricted variational distribution it should perform
at least as well. SGRLD improves on the performance of OVB and HSVG, but does not match the
performance of Gibbs sampling.

5.3 Results on Wikipedia corpus

The algorithms’ performances in an online scenario was assessed on a set of articles downloaded
at random from Wikipedia, as in [HBB10]. The vocabulary used is again as per [HBB10]; it is
not created from the Wikipedia data set, instead it is taken from the top 10,000 words in Project
Gutenburg texts, excluding all words of less than three characters. This results in vocabulary size
W of approximately 8000 words. 150,000 documents from Wikipedia were used in total, in mini-
batches of 50 documents each. The perplexities were estimated using the methods discussed in

7

(a) NIPS corpus

(b) Wikipedia corpus

Figure 2: Test-set perplexities on NIPS and Wikipedia corpora.

Section 5.1 on a separate holdout set of 1000 documents, split 90/10 training/test. As the corpus size
is large, collapsed Gibbs sampling was not run on this data set.
For each algorithm a grid-search was run on the hyper-parameters, step-size parameters, and num-
ber of Gibbs sampling sweeps / variational ﬁxed point iterations per π update. The lowest three
perplexities attained for each algorithm are shown in Figure 2(b). Corresponding parameters are
given in the supplementary material. HSVG achieves better performance than OVB, as expected.
The performance of SGRLD is a substantial improvement on both the variational algorithms.

6 Discussion

We have explored the issues involved in applying Langevin Monte Carlo techniques to a constrained
parameter space such as the probability simplex, and developed a novel online sampling algorithm
which addresses those issues. Using an expanded parametrisation with a reﬂection trick for negative
proposals removed the need to deal with boundary constraints, and using the Riemannian geometry
of the parameter space dealt with the problem of parameters with differing scales.
Applying the method to Latent Dirichlet Allocation on two data sets produced state of the art pre-
dictive performance for the same computational budget as competing methods, demonstrating that
full Bayesian inference using MCMC can be practically applied to models of interest, even when
the data set is large. Python code for our method is available at http://www.stats.ox.ac.
uk/˜teh/sgrld.html.
Due to the widespread use of models deﬁned on the probability simplex, we believe the methods
developed here for Langevin dynamics on the probability simplex will ﬁnd further uses beyond latent
Dirichlet allocation and stochastic gradient Monte Carlo methods. A drawback of SGLD algorithms
is the need for decreasing step sizes; it would be interesting to investigate adaptive step sizes and the
approximation entailed when using ﬁxed step sizes (but see [AKW12] for a recent development).

Acknowledgements

We thank the Gatsby Charitable Foundation and EPSRC (grant EP/K009362/1) for generous fund-
ing, reviewers and area chair for feedback and support, and [HBB10] for use of their excellent
publicly available source code.

8

0200400600800100014001600180020002200  HSVGOVBSGRLDCollapsed Gibbs0500001000001500001000120014001600180020002200  HSVGOVBSGRLDReferences
[ABW12]

[AKW12]

[Ama95]

Sungjin Ahn, Anoop Korattikara Balan, and Max Welling, Bayesian posterior sampling via
stochastic gradient ﬁsher scoring., ICML, 2012.
S. Ahn, A. Korattikara, and M. Welling, Bayesian posterior sampling via stochastic gradient
Fisher scoring, Proceedings of the International Conference on Machine Learning, 2012.
S. Amari, Information geometry of the EM and em algorithms for neural networks, Neural Net-
works 8 (1995), no. 9, 1379–1408.

[AWST09] A. Asuncion, M. Welling, P. Smyth, and Y. W. Teh, On smoothing and inference for topic models,
Proceedings of the International Conference on Uncertainty in Artiﬁcial Intelligence, vol. 25,
2009.
M. J. Beal, Variational algorithms for approximate bayesian inference, Ph.D. thesis, Gatsby Com-
putational Neuroscience Unit, University College London, 2003.
D. M. Blei, A. Y. Ng, and M. I. Jordan, Latent Dirichlet allocation, Journal of Machine Learning
Research 3 (2003), 993–1022.
M. Girolami and B. Calderhead, Riemann manifold Langevin and Hamiltonian Monte Carlo
methods, Journal of the Royal Statistical Society B 73 (2011), 1–37.

[BNJ03]

[Bea03]

[GC11]

[GCPT07] A. Globerson, G. Chechik, F. Pereira, and N. Tishby, Euclidean Embedding of Co-occurrence

Data, The Journal of Machine Learning Research 8 (2007), 2265–2295.
W. R. Gilks, S. Richardson, and D. J. Spiegelhalter, Markov chain monte carlo in practice, Chap-
man and Hall, 1996.
T. L. Grifﬁths and M. Steyvers, Finding scientiﬁc topics, Proceedings of the National Academy
of Sciences, 2004.

[HBB10] M. D. Hoffman, D. M. Blei, and F. Bach, Online learning for latent dirichlet allocation, Advances

[GRS96]

[GS04]

[Hec99]

[Ken78]
[Ken90]

[MHB12]

[Nea10]

[PSD00]

[RM51]

[RS02]

[Sat01]

[TNW07]

[WJ08]

[NASW09] D. Newman, A. Asuncion, P. Smyth, and M. Welling, Distributed algorithms for topic models,

in Neural Information Processing Systems, 2010.
D. Heckerman, A tutorial on learning with Bayesian networks, Learning in Graphical Models
(M. I. Jordan, ed.), Kluwer Academic Publishers, 1999.
J. Kent, Time-reversible diffusions, Advances in Applied Probability 10 (1978), 819–835.
A. D. Kennedy, The theory of hybrid stochastic algorithms, Probabilistic Methods in Quantum
Field Theory and Quantum Gravity, Plenum Press, 1990.
D. Mimno, M. Hoffman, and D. Blei, Sparse stochastic inference for latent Dirichlet allocation,
Proceedings of the International Conference on Machine Learning, 2012.

Journal of Machine Learning Research (2009).
R. M. Neal, MCMC using Hamiltonian dynamics, Handbook of Markov Chain Monte Carlo
(S. Brooks, A. Gelman, G. Jones, and X.-L. Meng, eds.), Chapman & Hall / CRC Press, 2010.
J.K. Pritchard, M. Stephens, and P. Donnelly, Inference of population structure using multilocus
genotype data, Genetics 155 (2000), 945–959.
H. Robbins and S. Monro, A stochastic approximation method, Annals of Mathematical Statistics
22 (1951), no. 3, 400–407.
G. O. Roberts and O. Stramer, Langevin diffusions and metropolis-hastings algorithms, Method-
ology and Computing in Applied Probability 4 (2002), 337–357, 10.1023/A:1023562417138.
M. Sato, Online model selection based on the variational Bayes, Neural Computation 13 (2001),
1649–1681.
Y. W. Teh, D. Newman, and M. Welling, A collapsed variational Bayesian inference algorithm for
latent Dirichlet allocation, Advances in Neural Information Processing Systems, vol. 19, 2007,
pp. 1353–1360.
M. J. Wainwright and M. I. Jordan, Graphical models, exponential families, and variational in-
ference, Foundations and Trends in Machine Learning 1 (2008), no. 1-2, 1–305.

[WMSM09] Hanna M. Wallach, Iain Murray, Ruslan Salakhutdinov, and David Mimno, Evaluation methods
for topic models, Proceedings of the 26th International Conference on Machine Learning (ICML)
(Montreal) (L´eon Bottou and Michael Littman, eds.), Omnipress, June 2009, pp. 1105–1112.
M. Welling and Y. W. Teh, Bayesian learning via stochastic gradient Langevin dynamics, Pro-
ceedings of the International Conference on Machine Learning, 2011.

[WT11]

9

